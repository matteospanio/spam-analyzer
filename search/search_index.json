{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A fast spam filter written in Python inspired by SpamAssassin integrated with machine learning.</p> <p> </p>"},{"location":"#what-is-spam-analyzer","title":"What is spam-analyzer?","text":"<p>spam-analyzer is a CLI (Command Line Interface) application that aims be a viable alternative to spam filter services.</p> <p>This program can classify the email given in inputs in spam or non-spam using a machine learning algorithm (Random Forest), the model is trained using a dataset of 19900 emails. Anyway it could be wrong sometimes, if you want to improve the accuracy of the model you can train it with your persolized dataset.</p> <p>The main features of spam-analyzer are:</p> <ol> <li>spam recognition with the option to display a detailed analysis of the email</li> <li>JSON output</li> <li>it can be used as a library in your Python project to extract features from an email</li> <li>it is written in Python with its most modern features to ensure software correctness</li> <li>extensible with plugins</li> <li>100% containerized with Docker</li> </ol>"},{"location":"#what-is-spam-and-how-does-spam-analyzer-know-it","title":"What is spam and how does spam-analyzer know it?","text":"<p>The analysis takes in consideration the following main aspects:</p> <ul> <li>the headers of the email</li> <li>the body of the email</li> <li>the attachments of the email</li> </ul> <p>The most significant parts are the headers and the body of the email. The headers are analyzed to extract the following features:</p> <ul> <li>SPF (Sender Policy Framework)</li> <li>DKIM (DomainKeys Identified Mail)</li> <li>DMARC (Domain-based Message Authentication, Reporting &amp; Conformance)</li> <li>If the sender domain is the same as the first in received headers</li> <li>The subject of the email</li> <li>The send date</li> <li>If the send date is compliant to the RFC 2822 and if it was sent from a valid time zone</li> <li>The date of the first received header</li> </ul> <p>While the body is analyzed to extract the following features:</p> <ul> <li>If there are links</li> <li>If there are images</li> <li>If links are only http or https</li> <li>The percentage of the body that is written in uppercase</li> <li>The percentage of the body that contains blacklisted words</li> <li>The polarity of the body calculated with TextBlob</li> <li>The subjectivity of the body calculated with TextBlob</li> <li>If it contains mailto links</li> <li>If it contains javascript code</li> <li>If it contains html code</li> <li>If it contains html forms</li> </ul> <p>About attachments we only know if they are present or not and if they are executable files.</p> <p>The task could be solved in a programmatic way, chaining a long set of <code>if</code> statements based on the features extracted from the email. However, this approach is not scalable and it is not easy to maintain. Moreover, it is not possible to improve the accuracy of the model without changing the code and, the most important, the analysis would be based on the conaissance of the programmer and not on the data. Since we live in the data era, we should use the data to solve the problem, not the programmer's knowledge. So I decided to use a machine learning algorithm to solve the problem using all the features extracted from the email.</p>"},{"location":"#license","title":"License","text":"<p>spam-analyzer is licensed under the GPLv3 license.</p> <p>This means that you can use, modify and distribute it freely, but you must give credits to the original authors.</p>"},{"location":"SECURITY/","title":"Security Policy","text":""},{"location":"SECURITY/#supported-versions","title":"Supported Versions","text":"<p>This software is currently in alpha testing. Only the latest release will be update for security issues.</p>"},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>To report a security vulnerability open the github security panel in this repository or click this link to create directly a new report. The mantainers will reply as soon as possible to let you know if the issue reported was taken in consideration.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p> <p>Note</p> <p>The Unreleased section is for changes that are not yet released, but are going to be released in the next version.</p>"},{"location":"changelog/#1011","title":"[1.0.11]","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>update dependencies</li> <li>update test gh workflow</li> </ul>"},{"location":"changelog/#1010","title":"[1.0.10]","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>update dependencies</li> <li>add python 3.12 to the supported versions</li> <li>update the documentation</li> <li>refactor coverage configuration inside pyproject.toml</li> </ul>"},{"location":"changelog/#109","title":"[1.0.9]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>py.typed file to make the package PEP 561 compliant</li> <li>missing type annotations</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>type annotations typos</li> <li>update dependencies</li> <li>erroneous docstrings</li> </ul>"},{"location":"changelog/#108","title":"[1.0.8]","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>update gitpython to fix security vulnerabilities</li> <li>update dependencies</li> </ul>"},{"location":"changelog/#1017","title":"[1.0.1..7]","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>updated dependencies to fix security vulnerabilities</li> </ul>"},{"location":"changelog/#100","title":"[1.0.0]","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>new specific domain for github pages docs, go to https://docs.spamanalyzer.tech</li> <li>getting_started.md page</li> <li>installation.md page</li> <li>integration tests for the CLI</li> <li>docker image for the CLI application</li> <li>has been added the <code>parse</code> method to the <code>SpamAnalyzer</code> class to parse a single mail, use that instead of the mailparser library to don't see unwanted logs</li> <li>pre-commit hooks to check the code before committing</li> <li>plugin system to extend the CLI application</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>changed to async methods for faster execution</li> <li>documentation is now generated with mkdocs</li> <li>refactored the code to use click instead of argparse</li> <li>refactored the code to separate the CLI from the library (also tests)</li> <li><code>MailAnalyzer</code> class has been renamed to `SpamAnalyzer</li> <li><code>MailAnalysis</code> class has no longer methods to decide if a mail is spam or not, those are now in the <code>SpamAnalyzer</code> class</li> <li>to make the package really modular, now the classification model can be injected in the <code>SpamAnalyzer</code> class (if not provided, the default one will be used)</li> <li>config folder is now created in the standard OS path for configuration files using click</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>configuration files are now properly installed</li> <li>now there's a better timezone detection and management</li> </ul>"},{"location":"changelog/#020-2023-07-17","title":"[0.2.0] - 2023-07-17","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>switched to poetry for dependency management</li> <li>updated all build/ci tools to use poetry</li> </ul>"},{"location":"getting_started/","title":"Getting started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<pre><code>pip install spam-analyzer\n</code></pre>"},{"location":"getting_started/#cli-tool","title":"CLI tool","text":"<p>Run <code>spam-analyzer --help</code> to see the available options.</p>"},{"location":"getting_started/#example","title":"Example","text":"<pre><code>spam-analyzer analyze email.txt\n</code></pre>"},{"location":"getting_started/#python-library","title":"Python library","text":"<pre><code>import asyncio\n\nfrom spamanalyzer import MailAnalysis, SpamAnalyzer\n\n\nasync def spam_analysis():\n    analysis_factory = SpamAnalyzer(wordlist=[\"spam\", \"phishing\", \"malware\"])\n    analysis: MailAnalysis = await analysis_factory.analyze(\"path/to/mail\")\n\n    return analysis\n\n\nanalysis = asyncio.run(spam_analysis())\nprint(analysis)\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#pip","title":"PIP","text":"<p>spam-analyzer is available on PyPI, so you can install it with pip:</p> <pre><code>pip install spam-analyzer\n</code></pre>"},{"location":"installation/#poetry","title":"Poetry","text":"<p>You can also install spam-analyzer with poetry as a dependency of your project:</p> <pre><code>poetry add spam-analyzer\n</code></pre>"},{"location":"installation/#source-code","title":"Source code","text":"<p>For the latest but not yet released version, you can install it from the source code:</p> PIPPoetry <pre><code>git clone https://github.com/matteospanio/spam-analyzer.git\ncd spam-analyzer\npip install .\n</code></pre> <pre><code>git clone https://github.com/matteospanio/spam-analyzer.git\ncd spam-analyzer\npoetry install # or poetry build\n</code></pre> <p>Note</p> <p>There are also two make targets that can be used to build the project:</p> <ul> <li><code>make build</code> to build the project</li> <li><code>make setup</code> to setup the development environment</li> </ul>"},{"location":"requirements/","title":"Requirements","text":"N\u00b0 Done Name Priority Description 1 \u2714\ufe0f Analyze single files high The app should take in input a single email file and analyze it. 2 \u2714\ufe0f Analyze a list of files high The app should take in input a list of email files and analyze them. 3 \u2714\ufe0f Handle non-mail files high The app should gently handle non email files, notifying to the user a wrong input, but should not stop its execution 4 \u2714\ufe0f Display results to STDOUT high The app should display an interface with a detailed analysis of each file taken in input 5 \ud83d\udea7 Output the analysis results high The app should output the analysis results in varoius formats (currently only json is aviable) to make possible further analysis with other tools 6 \u274c Fast analysis high The analysis should be parallelized to make it faster where possible 7 \u274c Train the model on your own dataset medium The app should be able to personalize the ML model using a dataset provided by the user. 8 \u274c Accept <code>.mbox</code> files as input low The app should be able to handle <code>.mbox</code> files in inputs <p>\u2714\ufe0f = done | \ud83d\udea7 = in progress | \u274c = todo</p>"},{"location":"testing/","title":"Testing","text":"<p>Tests are a great way to ensure that your code is working as expected, and that it continues to work as expected as you make changes to your code.</p> <p>For a better development flow I suggest to follow the TDD paradigm (Test Driven Development), it consists in writing tests before implementing functionalities in a top-down approach to programming. Anyway, even if you don't follow the TDD rules you should provide tests for the code you write.</p>"},{"location":"testing/#strategies","title":"Strategies","text":"<ol> <li> <p>Bottom-up: every single components should have a unit test covering its base and limit cases and then </p> </li> <li> <p>Black-box: after testing how the code works we should ensure that it actually works, so at the end of the testing we consider the requirements and see if they are respected.</p> </li> </ol>"},{"location":"testing/#automation","title":"Automation","text":"<p>The test suite is automated with pytest, to run tests go to the root directory of the project and type <code>make test</code>, the makefile will handle the tests launch with proper options; otherwise you can just open the console and run <code>pytest</code>. Pytest will automatically generate cache foldes and files, to delete them you can type <code>make clean</code>.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#cli","title":"CLI","text":"<p>spam-analyzer can be used as a CLI application:</p> <pre><code>Usage: spam-analyzer [OPTIONS] COMMAND [ARGS]...\n\n  A simple program to analyze emails.\n\nOptions:\n  -h, --help                Show this message and exit.\n  -v, --verbose             Enables verbose mode.\n  --version                 Show the version and exit.\n  -C, --config CONFIG_PATH  Location of the configuration file. Supports glob\n                            pattern of local path and remote URL.\n\nCommands:\n  analyze    Analyze emails from a file or directory.\n  configure  Configure the program.\n  plugins    Show all available plugins.\n</code></pre> <ul> <li><code>spam-analyzer analyze &lt;file&gt;</code>: classify the email given in input</li> <li><code>spam-analyzer -v analyze &lt;file&gt;</code>: classify the email given in input and display a detailed analysis<sup>1</sup></li> <li><code>spam-analyzer analyze -fmt json &lt;file&gt;</code>: classify the email given in input and display the result in JSON format (useful for integration with other programs)</li> <li><code>spam-analyzer analyze -fmt json -o &lt;outpath&gt; &lt;file&gt;</code>: classify the email given in input and write the result in JSON format in the file given in input<sup>2</sup></li> <li><code>spam-analyzer analyze -l &lt;wordlist&gt; &lt;file&gt;</code>: classify the email given in input using the wordlist given in input</li> </ul>"},{"location":"usage/#configuration","title":"Configuration","text":"<p><code>spam-analyzer</code> is thought to be highly configurable: on its first execution it will create a configuration file in <code>~/.config/spamanalyzer/</code> with some other default files. You can change the configuration file to customize the behavior of the program. At the moment of writing there are only paths to the wordlist and the model, but in the future there will be more options (e.g. senders blacklist and whitelist, a default path where to copy classified emails,...).</p>"},{"location":"usage/#python-library","title":"Python library","text":"<pre><code>import asyncio\n\nfrom spamanalyzer import MailAnalysis, SpamAnalyzer\n\n\nasync def spam_analysis():\n    analysis_factory = SpamAnalyzer(wordlist=[\"spam\", \"phishing\", \"malware\"])\n    analysis: MailAnalysis = await analysis_factory.analyze(\"path/to/mail\")\n\n    return analysis\n\n\nanalysis = asyncio.run(spam_analysis())\nprint(analysis)\n</code></pre> <p>The <code>spamanalyzer</code> library provides a really simple interface to extract features from an email. The <code>SpamAnalyzer</code> class provides the <code>analyze</code> method that takes in input the path to the email and returns a <code>MailAnalysis</code> object containing the analysis of the email.</p> <p>Furthermore, the <code>MailAnalysis</code> class provides the <code>is_spam</code> method that returns <code>True</code> if the email is spam, <code>False</code> otherwise. Further examples are available in the folder <code>examples</code> of the source code.</p> <ol> <li> <p>The <code>--verbose</code> option is available only for the first use case, it will not work in combination with the <code>--output-format</code> option.\u00a0\u21a9</p> </li> <li> <p>You should use the <code>--output-file</code> instead of the <code>&gt;</code> operator to write the output in a file, because the <code>spam-analyzer</code> program prints some other information on the standard output while processing the email(s).\u00a0\u21a9</p> </li> </ol>"},{"location":"api/","title":"API reference","text":""},{"location":"api/reference/","title":"API","text":"<p>The package contains the main classes and functions used to analyze the emails.</p>"},{"location":"api/reference/#spamanalyzer--abstraction","title":"Abstraction","text":"<p>In information technology, abstraction is the process of hiding the implementation details from the user and it is one of the three fundamental concepts of object-oriented programming (OOP).</p> <p>Here we use abstraction to hide the complexity of the email analysis process from the user. And provide a simple interface to use the package. The following code showes the core concept of this package: <pre><code>from spamanalyzer.analyzer import MailAnalyzer\n\nanalyser = MailAnalyzer(wordlist)\nanalysis = analyser.analyze(email_path) # in the future we will support asynchroneous\nanalysis\n\nanalysis.is_spam()\n</code></pre> we istantiate the <code>MailAnalyzer</code> class and pass the wordlist to it. Then we call the <code>analyze</code> method to get the analysis of the email: in this way we can also parallelize the analysis of multiple emails.</p>"},{"location":"api/reference/#spamanalyzer.Date","title":"<code>Date</code>","text":"<p>A date object, it is used to store the date of the email and to perform some checks on it.</p> <p>The focus of the checks is to determine if the date is valid and if it is in the correct format. The date is valid if it is in the RFC2822 format and if the timezone is valid:</p> <ul> <li>RFC2822: specifies the   format of the date in the headers of the mail in the form   <code>Day, DD Mon YYYY HH:MM:SS TZ</code>. Of course it is not the only format used in the   headers, but it is the most common, so it is the one we use to check if the   date is valid.</li> <li>TZ: specifies   the timezone of the date. We included this check since often malicious emails   can have a weird behavior, it is not uncommon to see a not existing timezone   in the headers of the mail (valid timezones are from -12 to +14).</li> </ul>"},{"location":"api/reference/#spamanalyzer.Date.day","title":"<code>day: int</code>  <code>property</code>","text":"<p>Get the day of the date.</p>"},{"location":"api/reference/#spamanalyzer.Date.hour","title":"<code>hour: int</code>  <code>property</code>","text":"<p>Get the hour of the date.</p>"},{"location":"api/reference/#spamanalyzer.Date.minutes","title":"<code>minutes: int</code>  <code>property</code>","text":"<p>Get the minutes of the date.</p>"},{"location":"api/reference/#spamanalyzer.Date.month","title":"<code>month: int</code>  <code>property</code>","text":"<p>Get the month of the date.</p>"},{"location":"api/reference/#spamanalyzer.Date.seconds","title":"<code>seconds: int</code>  <code>property</code>","text":"<p>Get the seconds of the date.</p>"},{"location":"api/reference/#spamanalyzer.Date.timezone","title":"<code>timezone: int</code>  <code>property</code>","text":"<p>Get the timezone of the date.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The timezone of the date, if the timezone is not found it returns 0</p>"},{"location":"api/reference/#spamanalyzer.Date.year","title":"<code>year: int</code>  <code>property</code>","text":"<p>Get the year of the date. It raises a ValueError if the year is less than 1971 since the first email was sent in 1971.</p> <p>See</p> <p>history of email to know more about the first email sent.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the year is less than 1971</p>"},{"location":"api/reference/#spamanalyzer.Date.is_RFC2822_formatted","title":"<code>is_RFC2822_formatted()</code>","text":"<p>Check if the date is in the RFC2822 format.</p>"},{"location":"api/reference/#spamanalyzer.Date.is_tz_valid","title":"<code>is_tz_valid()</code>  <code>cached</code>","text":"<p>The timezone is valid if it is in the range [-12, 14]</p>"},{"location":"api/reference/#spamanalyzer.Domain","title":"<code>Domain</code>  <code>dataclass</code>","text":"<p>A Domain is a class representing an internet domain, here you can get information about the target domain.</p> <p>The constructor resolves any domain alias to the real domain name: in fact common domain names are aliases for more complex server names that would be difficult to remember for common users, since there is not a direct method in the <code>socket</code> module to resolve domain aliases, we use the <code>gethostbyname</code> chained with the <code>gethostbyaddr</code> methods this way makes the instatiation of the class slower, but it is the only way to get the real domain name.</p>"},{"location":"api/reference/#spamanalyzer.Domain.from_ip","title":"<code>from_ip(ip_addr)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Create a Domain object from an ip address. It translate the ip address to its domain name via the <code>socket.gethostbyaddr</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>ip_addr</code> <code>str</code> <p>the targetted ip address</p> required <p>Returns:</p> Name Type Description <code>Domain</code> <code>Self</code> <p>the domain obtained from the ip address</p>"},{"location":"api/reference/#spamanalyzer.Domain.from_string","title":"<code>from_string(domain_str)</code>  <code>classmethod</code>","text":"<p>Instantiate a Domain object from string, it is a wrapper of the <code>self.__init__</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>domain_str</code> <code>str</code> <p>a string containing a domain to be parsed</p> required <p>Returns:</p> Name Type Description <code>Domain</code> <code>Self</code> <p>the domain obtained from the string</p>"},{"location":"api/reference/#spamanalyzer.Domain.get_ip_address","title":"<code>get_ip_address()</code>  <code>async</code>","text":"<p>Translate the domain name to its ip address querying the DNS server.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the ip address of the domain</p> <p>Note: this method is async since it performs a network request</p>"},{"location":"api/reference/#spamanalyzer.Domain.is_subdomain","title":"<code>is_subdomain(domain)</code>","text":"<p>Is the domain a subdomain of the given domain?</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>Domain</code> <p>the reference domain</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the domain is a subdomain of the given domain,</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>if the given object is not a Domain</p> <p>Note: a domain is a subdomain of itself</p>"},{"location":"api/reference/#spamanalyzer.Domain.is_superdomain","title":"<code>is_superdomain(domain)</code>","text":"<p>Is the domain a superdomain of the given domain?</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>Domain</code> <p>the reference domain</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the domain is a superdomain of the given domain,</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>if the given object is not a Domain</p> <p>Note: a domain is a superdomain of itself</p>"},{"location":"api/reference/#spamanalyzer.Domain.relation","title":"<code>relation(domain)</code>","text":"<p>Define the relation between two domains.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>Domain</code> <p>the domain to compare with</p> required <p>Returns:</p> Name Type Description <code>DomainRelation</code> <code>DomainRelation</code> <p>the relation between the two domains</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>if the given object is not a Domain</p>"},{"location":"api/reference/#spamanalyzer.MailAnalysis","title":"<code>MailAnalysis</code>  <code>dataclass</code>","text":"<p>A summary of the analysis of a mail.</p>"},{"location":"api/reference/#spamanalyzer.MailAnalysis.attachments","title":"<code>attachments: dict[str, bool]</code>  <code>instance-attribute</code>","text":"<p>It is a dictionary containing a detailed analysis of the mail's attachments. It contains the following keys:</p> Key Type Description <code>has_attachments</code> bool flag that indicates if the mail has attachments <code>attachment_is_executable</code> bool flag that indicates if the mail has an attachment in executable format"},{"location":"api/reference/#spamanalyzer.MailAnalysis.body","title":"<code>body: dict[str, bool | float]</code>  <code>instance-attribute</code>","text":"<p>It is a dictionaty containing a detailed analysis of the mail's body. It contains the following keys:</p> Key Type Description <code>contains_html</code> bool flag that indicates if the body contains an html tag <code>contains_script</code> bool flag that indicates if the body contains a script tag or a callback function <code>forbidden_words_percentage</code> float the rate of forbidden words in the body of the mail, it is a float between 0 and 1 <code>has_links</code> bool flag that indicates if the body contains an url <code>has_mailto</code> bool flag that indicates if the body contains a mailto link <code>https_only</code> bool flag that indicates if the body contains only https links <code>contains_form</code> bool flag that indicates if the body contains a form tag <code>has_images</code> bool flag that indicates if the body contains an image <code>is_uppercase</code> bool flag that indicates if the body is in uppercase more than \\(60\\)% of its length <code>text_polarity</code> float the polarity of the body, it is a float between -1 and 1 <code>text_subjectivity</code> float the subjectivity of the body, it is a float between 0 and 1"},{"location":"api/reference/#spamanalyzer.MailAnalysis.file_path","title":"<code>file_path: str</code>  <code>instance-attribute</code>","text":"<p>The path of the file analyzed.</p>"},{"location":"api/reference/#spamanalyzer.MailAnalysis.headers","title":"<code>headers: dict</code>  <code>instance-attribute</code>","text":"<p>It is a dictionaty containing a detailed analysis of the mail's headers. It contains the following keys:</p> Key Type Description <code>has_spf</code> bool flag that indicates if the mail has a SPF header <code>has_dkim</code> bool flag that indicates if the mail has a DKIM header <code>has_dmarc</code> bool flag that indicates if the mail has a DMARC header <code>auth_warn</code> bool flag that indicates if the mail has an Authentication-Warning header <code>domain_matches</code> bool flag that indicates if the domain of the sender matches the first domain in the <code>Received</code> headers <code>has_suspect_subject</code> bool flag that indicates if the mail's subject contains a suspicious word or a gappy word (e.g. <code>H*E*L*L*O</code>) <code>subject_is_uppercase</code> bool flag that indicates if the mail's subject is in uppercase <code>send_date</code> Date the date when the mail was sent, if the mail has no <code>Date</code> header, it is <code>None</code> <code>received_date</code> Date the date when the mail was received, if the mail hasn't a date in <code>Received</code> header, it is <code>None</code> <ul> <li><code>has_spf</code>, it is <code>True</code> if the mail has a SPF header (Sender Policy Framework),   it is a standard to prevent email spoofing.   The SPF record is a TXT record that contains a policy that specifies which mail   servers are allowed to send email from a specified domain.</li> <li><code>has_dkim</code>, it is <code>True</code> if the mail has a DKIM header   (DomainKeys Identified Mail).   The DKIM signature is a digital signature that is added to an email message to   verify that the message has not been altered since it was signed.</li> <li><code>has_dmarc</code>, it is <code>True</code> if the mail has a DMARC header (Domain-based Message   Authentication, Reporting &amp; Conformance).   The DMARC record is a type of DNS record that is used to help email receivers   determine whether an email is legitimate or not.</li> <li><code>auth_warn</code>, it is <code>True</code> if the mail has an Authentication-Warning header   The Authentication-Warning header is used to indicate that the message has been   modified in transit.</li> <li><code>domain_matches</code>, it is <code>True</code> if the domain of the sender matches the first   domain in the <code>Received</code> headers</li> <li><code>has_suspect_subject</code>, it is <code>True</code> if the mail's subject contains a suspicious   word or a gappy word (e.g. <code>H*E*L*L*O</code>)</li> <li><code>subject_is_uppercase</code>, it is <code>True</code> if the mail's subject is in uppercase</li> <li><code>send_date</code>, it is the date when the mail was sent in a <code>Date</code> object,   if the mail has no <code>Date</code> header, it is <code>None</code></li> <li><code>received_date</code>, it is the date when the mail was received in a <code>Date</code> object,   if the mail hasn't a date in <code>Received</code> header, it is <code>None</code></li> </ul>"},{"location":"api/reference/#spamanalyzer.SpamAnalyzer","title":"<code>SpamAnalyzer</code>","text":"<p>Analyze a mail and return a <code>MailAnalysis</code> object, essentially it is a factory of <code>MailAnalysis</code>.</p> <p>The <code>MailAnalyzer</code> object provides two methods to analyze a mail:</p> <ul> <li><code>analyze</code> to analyze a mail from a file, it returns a <code>MailAnalysis</code>   object containing a description of the headers, body and attachments of the mail</li> <li><code>get_domain</code> to get the domain of the mail from the headers,   it returns a <code>Domain</code> object</li> </ul> <p>The core of the analysis is the <code>analyze</code> method, it uses the <code>MailParser</code> class (from <code>mailparser</code> library) to parse the mail. The analysis is based on separated checks for the headers, body and attachments and each check is implemented in a separated function: this make the analysis modular and easy to extend in future versions.</p>"},{"location":"api/reference/#spamanalyzer.SpamAnalyzer.classify_multiple_input","title":"<code>classify_multiple_input(mails)</code>","text":"<p>Classify a list of mails.</p> <p>Parameters:</p> Name Type Description Default <code>mails</code> <code>list[MailAnalysis]</code> <p>a list of mails to be classified</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>List[bool]</code> <p>a list of boolean values, <code>True</code> if the mail is spam, <code>False</code></p> <code>List[bool]</code> <p>otherwise</p>"},{"location":"api/reference/#spamanalyzer.SpamAnalyzer.is_spam","title":"<code>is_spam(email)</code>","text":"<p>Determine if the email is spam based on the analysis of the mail.</p>"},{"location":"api/utils/","title":"spamanalyzer.utils","text":""},{"location":"api/utils/#spamanalyzer.utils.analyze_subject","title":"<code>analyze_subject(headers, wordlist)</code>","text":"<p>Checks if the email has gappy words or forbidden words in the subject.</p> <p>Parameters:</p> Name Type Description Default <code>headers</code> <code>dict</code> <p>a dictionary containing parsed email headers</p> required <code>wordlist</code> <code>list[str]</code> <p>a list of words to be used as a spam filter in the subject</p> required"},{"location":"api/utils/#spamanalyzer.utils.dkim_pass","title":"<code>dkim_pass(headers)</code>","text":"<p>Checks if the email has a DKIM record.</p>"},{"location":"api/utils/#spamanalyzer.utils.dmarc_pass","title":"<code>dmarc_pass(headers)</code>","text":"<p>Checks if the email has a DMARC record.</p>"},{"location":"api/utils/#spamanalyzer.utils.get_domain","title":"<code>get_domain(field)</code>  <code>async</code>","text":"<p>Extracts the domain from a field.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>a string expected to contain a domain</p> required <p>Returns:</p> Name Type Description <code>Domain</code> <p>a Domain object containing the domain name and the TLD</p>"},{"location":"api/utils/#spamanalyzer.utils.has_auth_warning","title":"<code>has_auth_warning(headers)</code>","text":"<p>Checks if the email has an authentication warning, usually it means that the sender claimed to be someone else.</p>"},{"location":"api/utils/#spamanalyzer.utils.has_html","title":"<code>has_html(body)</code>","text":"<p>Checks if the email contains html tags.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the email contains html tags</p>"},{"location":"api/utils/#spamanalyzer.utils.has_html_form","title":"<code>has_html_form(body)</code>","text":"<p>Checks if the email has a form.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the email has a form</p>"},{"location":"api/utils/#spamanalyzer.utils.has_images","title":"<code>has_images(body)</code>","text":"<p>Checks if the email contains images.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the email contains images</p>"},{"location":"api/utils/#spamanalyzer.utils.has_mailto_links","title":"<code>has_mailto_links(body)</code>","text":"<p>Checks if the email has mailto links.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the email has mailto links</p>"},{"location":"api/utils/#spamanalyzer.utils.has_script_tag","title":"<code>has_script_tag(body)</code>","text":"<p>Checks if the email has script tags or javascript code.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the email has script tags or javascript code</p>"},{"location":"api/utils/#spamanalyzer.utils.inspect_attachments","title":"<code>inspect_attachments(attachments)</code>","text":"<p>A detailed analysis of the email attachments.</p> <p>Parameters:</p> Name Type Description Default <code>attachments</code> <code>List</code> <p>a list of attachments</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, bool]</code> <p>a dictionary containing the following information:</p> <code>dict[str, bool]</code> <p>```python</p> <code>dict[str, bool]</code> <p>{ \"has_attachments\": bool,         # True if the email has attachments \"attachment_is_executable\": bool # True if the email has                                  # an attachment in executable format</p> <code>dict[str, bool]</code> <p>}</p>"},{"location":"api/utils/#spamanalyzer.utils.inspect_body","title":"<code>inspect_body(body, wordlist, domain)</code>","text":"<p>A detailed analysis of the email body.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <code>wordlist</code> <code>list[str]</code> <p>a list of words to be used as a spam filter in the body</p> required <code>domain</code> <code>Domain</code> <p>the domain of the sender</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>a dictionary containing the following information:</p> <ul> <li>has_http_links (bool): True if the email has http links</li> <li>has_script (bool): True if the email has script tags or javascript code</li> <li>forbidden_words_percentage (float): the percentage of forbidden words in the body</li> <li>has_form (bool): True if the email has a form</li> <li>contains_html (bool): True if the email contains html tags</li> </ul>"},{"location":"api/utils/#spamanalyzer.utils.inspect_headers","title":"<code>inspect_headers(email, wordlist)</code>  <code>async</code>","text":"<p>A detailed analysis of the email headers.</p> <p>Parameters:</p> Name Type Description Default <code>headers</code> <code>dict</code> <p>a dictionary containing parsed email headers</p> required <code>wordlist</code> <code>Iterable[str]</code> <p>a list of words to be used as a spam filter in the</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>a tuple containing all the results of the analysis</p> <ul> <li>has_spf (bool): True if the email has a SPF record</li> <li>has_dkim (bool): True if the email has a DKIM record</li> <li>has_dmarc (bool): True if the email has a DMARC record</li> <li>domain_matches (bool): True if the domain of the sender matches the domain of   the server</li> <li>has_auth_warning (bool): True if the email has an authentication warning</li> <li>has_suspect_words (bool): True if the email has gappy words or forbidden words   in the subject</li> <li>send_year (int): the year in which the email was sent (in future versions should   be a datetime object)</li> </ul>"},{"location":"api/utils/#spamanalyzer.utils.parse_date","title":"<code>parse_date(headers, timezone)</code>","text":"<p>Date format should follow RFC 2822, this function expects a date in the format: \"Wed, 21 Oct 2015 07:28:00 -0700\", and returns a tuple where: 1. the first element is the parsed date or <code>None</code> if the date is not in the correct   format 2. the second element is a boolean indicating if the date is valid or not</p> <p>Eventually in future versions will be specified the kind of error that occurred, like in spamassassin (e.g. \"invalid date\", \"absurd tz\", \"future date\")</p>"},{"location":"api/utils/#spamanalyzer.utils.percentage_of_bad_words","title":"<code>percentage_of_bad_words(body, wordlist)</code>","text":"<p>Calculates the percentage of forbidden words in the body.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>str</code> <p>the body of the email</p> required <code>wordlist</code> <code>list[str]</code> <p>a list of words to be used as a spam filter in the body</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the percentage of forbidden words in the body</p>"},{"location":"api/utils/#spamanalyzer.utils.spf_pass","title":"<code>spf_pass(headers)</code>","text":"<p>Checks if the email has a SPF record.</p>"},{"location":"contrib/CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"contrib/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"contrib/CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at . All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"contrib/CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"contrib/CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contrib/contributing/","title":"How to contribute","text":"<p>Contributors are welcome!</p> <p>Info</p> <p>Everyone should feel free to talk about the project, ask questions, propose new features, report bugs, and so on. We are here to help each other and make the project better.</p> <p>For a peaceful and respectful environment, we have a Code of Conduct that applies to all the spaces of the project.</p>"},{"location":"contrib/contributing/#reporting-bugs","title":"Reporting bugs","text":"<p>If you find a bug in the program please open an issue in the issue tracker and describe the problem you have found. If you can, please provide a minimal example that reproduces the problem. If you have a solution for the problem, please open a pull request.</p> <p>Warning</p> <p>For security issues please refer to the security policy.</p>"},{"location":"contrib/contributing/#developers-guide","title":"Developer's guide","text":"<p>Our priorities are:</p> <ul> <li>high quality and readability of code and documentation</li> <li>provide a test for every functionalities implemented</li> </ul>"},{"location":"contrib/contributing/#setting-up-the-environment","title":"Setting up the environment","text":"<p>The project uses poetry for dependency management, so you need to install it first.</p> <p>Once you have installed poetry run <code>make setup</code> and you are done, now you can start tweak spam-analyzer making it better.</p>"},{"location":"contrib/contributing/#building","title":"Building","text":"<p>To build the package locally run in the root folder of the project <code>make build</code>, it will create a local build that can be tested in your environment.</p> <p>Even if you are not a developer you can contribute to the project donating a little fee to who invests his time in making reliable software for free. Every kind of support are welcome.</p>"},{"location":"data_analysis/","title":"Data Analysis","text":"<p>A detailed analysis of the model is available in the model evaluation page.</p>"},{"location":"data_analysis/#the-dataset","title":"The Dataset","text":"<p>The dataset is a composition of spam and non-spam messages. They were taken from the SpamAssassin Public Corpus, untroubled.org and personal emails.</p>"},{"location":"data_analysis/SpamAnalysis/","title":"Models Evaluation","text":"<p>The dataset has been created from a mixture of sources:</p> <ul> <li>my personal email archives</li> <li>the spamassassin corpus (it's really old)</li> <li>the SPAM archive by untroubled</li> </ul> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import the dataset\ndataset = pd.read_csv(\"data/spam.csv\")\n</pre> import pandas as pd import matplotlib.pyplot as plt %matplotlib inline  # import the dataset dataset = pd.read_csv(\"data/spam.csv\") <p>Here we have many features that have been extracted with <code>spamanalyzer</code> library: there are headers and body analysis. The expected label is the column <code>is_spam</code></p> In\u00a0[2]: Copied! <pre>dataset.info()\n</pre> dataset.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 19901 entries, 0 to 19900\nData columns (total 24 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   has_spf                         19901 non-null  bool   \n 1   has_dkim                        19901 non-null  bool   \n 2   has_dmarc                       19901 non-null  bool   \n 3   domain_matches                  19901 non-null  bool   \n 4   auth_warn                       19901 non-null  bool   \n 5   has_suspect_subject             19901 non-null  bool   \n 6   subject_is_uppercase            19901 non-null  bool   \n 7   send_date_is_RFC2822_compliant  19901 non-null  bool   \n 8   send_date_tz_is_valid           19901 non-null  bool   \n 9   has_received_date               19901 non-null  bool   \n 10  uppercase_body                  19901 non-null  bool   \n 11  script                          19901 non-null  bool   \n 12  images                          19901 non-null  bool   \n 13  https_only                      19901 non-null  bool   \n 14  mailto                          19901 non-null  bool   \n 15  links                           19901 non-null  bool   \n 16  bad_words_percentage            19901 non-null  float64\n 17  html                            19901 non-null  bool   \n 18  form                            19901 non-null  bool   \n 19  polarity                        19901 non-null  float64\n 20  subjectivity                    19901 non-null  float64\n 21  attachments                     19901 non-null  bool   \n 22  attach_is_executable            19901 non-null  bool   \n 23  is_spam                         19901 non-null  int64  \ndtypes: bool(20), float64(3), int64(1)\nmemory usage: 1010.7 KB\n</pre> In\u00a0[21]: Copied! <pre>import seaborn as sns\n\nham  = dataset[dataset[\"is_spam\"] == 0]\nspam = dataset[dataset[\"is_spam\"] == 1]\n\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,7))\nfig.suptitle('Data distribution', c='r')\n\ndata = [len(ham)/len(ham+spam), len(spam)/len(ham+spam)]\nlabels = ['ham', 'spam']\ncolors = ['steelblue', 'red']\n\naxes[0].pie(data, labels = labels, autopct='%.0f%%', colors=colors)\n\nsns.countplot(x = ['ham']*len(ham) + ['spam']*len(spam), palette=colors, ax=axes[1]);\n</pre> import seaborn as sns  ham  = dataset[dataset[\"is_spam\"] == 0] spam = dataset[dataset[\"is_spam\"] == 1]  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,7)) fig.suptitle('Data distribution', c='r')  data = [len(ham)/len(ham+spam), len(spam)/len(ham+spam)] labels = ['ham', 'spam'] colors = ['steelblue', 'red']  axes[0].pie(data, labels = labels, autopct='%.0f%%', colors=colors)  sns.countplot(x = ['ham']*len(ham) + ['spam']*len(spam), palette=colors, ax=axes[1]); <p>PCA makes possible to reduce the dimensions of the dataset, this way is possible to plot data in a 2d plot</p> In\u00a0[5]: Copied! <pre># split the dataset in features and labels\nX = dataset.drop(\"is_spam\", axis=1)\ny = dataset[\"is_spam\"]\n</pre> # split the dataset in features and labels X = dataset.drop(\"is_spam\", axis=1) y = dataset[\"is_spam\"] In\u00a0[28]: Copied! <pre>from mpl_toolkits import mplot3d\nfrom sklearn.decomposition import PCA\n\nfig = plt.figure(figsize=(15, 7))\ncolors = ['steelblue', 'red']\n\n# 2d plot\nax = fig.add_subplot(1, 2, 1)\nX_2 = PCA(n_components=2).fit_transform(X)\nemails = pd.DataFrame(X_2)\nax.scatter(emails[0], emails[1], c=y)\n\n# 3d plot\nax = fig.add_subplot(1, 2, 2, projection='3d')\nX_3 = PCA(n_components=3).fit_transform(X)\nemails = pd.DataFrame(X_3)\n\nax.scatter(emails[0], emails[1], emails[2], c=y);\n</pre> from mpl_toolkits import mplot3d from sklearn.decomposition import PCA  fig = plt.figure(figsize=(15, 7)) colors = ['steelblue', 'red']  # 2d plot ax = fig.add_subplot(1, 2, 1) X_2 = PCA(n_components=2).fit_transform(X) emails = pd.DataFrame(X_2) ax.scatter(emails[0], emails[1], c=y)  # 3d plot ax = fig.add_subplot(1, 2, 2, projection='3d') X_3 = PCA(n_components=3).fit_transform(X) emails = pd.DataFrame(X_3)  ax.scatter(emails[0], emails[1], emails[2], c=y); <p>We see some overlap between the two classes, but it's possible to see that the spam emails are more concentrated in the lower left corner</p> In\u00a0[8]: Copied! <pre>from sklearn.model_selection import train_test_split\n# split in train and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n</pre> from sklearn.model_selection import train_test_split # split in train and test datasets X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42) In\u00a0[8]: Copied! <pre>%%time\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ntc = DecisionTreeClassifier()\n\nparams = {\n    'min_samples_split': [2, 5, 10, 20, 30, 50, 60],\n    'min_samples_leaf': [1, 2, 5, 10, 20, 30, 40, 50, 60],\n    'max_leaf_nodes': [x for x in range(2, 121, 2)]\n}\n\ngscv = GridSearchCV(\n    estimator=tc,\n    return_train_score=True,\n    param_grid=params,\n    verbose=1,\n    n_jobs=-1\n)\n\ngscv.fit(X_train, y_train)\n\ngscv.best_params_\n</pre> %%time from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import GridSearchCV  tc = DecisionTreeClassifier()  params = {     'min_samples_split': [2, 5, 10, 20, 30, 50, 60],     'min_samples_leaf': [1, 2, 5, 10, 20, 30, 40, 50, 60],     'max_leaf_nodes': [x for x in range(2, 121, 2)] }  gscv = GridSearchCV(     estimator=tc,     return_train_score=True,     param_grid=params,     verbose=1,     n_jobs=-1 )  gscv.fit(X_train, y_train)  gscv.best_params_ <pre>Fitting 5 folds for each of 3780 candidates, totalling 18900 fits\nCPU times: user 4.61 s, sys: 646 ms, total: 5.25 s\nWall time: 1min 4s\n</pre> Out[8]: <pre>{'max_leaf_nodes': 120, 'min_samples_leaf': 1, 'min_samples_split': 20}</pre> In\u00a0[12]: Copied! <pre>import numpy as np\n\nplot_grid_search_validation_curve(gscv, \"max_leaf_nodes\", ylim=[0.7, 0.95])\n</pre> import numpy as np  plot_grid_search_validation_curve(gscv, \"max_leaf_nodes\", ylim=[0.7, 0.95]) In\u00a0[13]: Copied! <pre>plot_grid_search_validation_curve(gscv, \"min_samples_leaf\", ylim=[0.85, 0.95])\n</pre> plot_grid_search_validation_curve(gscv, \"min_samples_leaf\", ylim=[0.85, 0.95]) In\u00a0[14]: Copied! <pre>plot_grid_search_validation_curve(gscv, \"min_samples_split\", ylim=[0.88, 0.94])\n</pre> plot_grid_search_validation_curve(gscv, \"min_samples_split\", ylim=[0.88, 0.94]) In\u00a0[15]: Copied! <pre>from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(\n    max_leaf_nodes=120,\n    min_samples_leaf=1,\n    min_samples_split=20,\n    random_state=42,\n    splitter='best'\n)\n\ntree.fit(X_train, y_train)\n</pre> from sklearn.tree import DecisionTreeClassifier  tree = DecisionTreeClassifier(     max_leaf_nodes=120,     min_samples_leaf=1,     min_samples_split=20,     random_state=42,     splitter='best' )  tree.fit(X_train, y_train) Out[15]: <pre>DecisionTreeClassifier(max_leaf_nodes=120, min_samples_split=20,\n                       random_state=42)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier<pre>DecisionTreeClassifier(max_leaf_nodes=120, min_samples_split=20,\n                       random_state=42)</pre> In\u00a0[16]: Copied! <pre>tree.feature_importances_\n</pre> tree.feature_importances_ Out[16]: <pre>array([0.4016611 , 0.01811475, 0.        , 0.00676701, 0.00182249,\n       0.00172735, 0.03214049, 0.00293565, 0.01252585, 0.00789527,\n       0.00129854, 0.0009133 , 0.24933753, 0.00520886, 0.01514014,\n       0.00183443, 0.03398189, 0.02640206, 0.00264756, 0.08749609,\n       0.05883771, 0.03131193, 0.        ])</pre> In\u00a0[17]: Copied! <pre>y_pred = tree.predict(X_test)\n</pre> y_pred = tree.predict(X_test) In\u00a0[18]: Copied! <pre>from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)\n</pre> from sklearn.metrics import accuracy_score  accuracy_score(y_test, y_pred) Out[18]: <pre>0.9065561416729465</pre> In\u00a0[19]: Copied! <pre>from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfig, ax = plt.subplots(figsize=(100,70))\nplot_tree(tree, ax=ax,\n          precision=7,\n          feature_names=X_train.columns.to_list(),\n          filled=True, rounded=True);\n</pre> from sklearn.tree import plot_tree import matplotlib.pyplot as plt %matplotlib inline  fig, ax = plt.subplots(figsize=(100,70)) plot_tree(tree, ax=ax,           precision=7,           feature_names=X_train.columns.to_list(),           filled=True, rounded=True); In\u00a0[20]: Copied! <pre>import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\nconf_mx = confusion_matrix(y_test, tree.predict(X_test))\n\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7))\nfig.suptitle('Confusion matrix', c='r')\nsns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True, \n            fmt='.2%', cmap='Blues')\naxes[0].set_xlabel('Predicted labels')\naxes[0].set_ylabel('Actual labels')\n\nsns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='')\naxes[1].set_xlabel('Predicted labels')\naxes[1].set_ylabel('Actual labels');\n</pre> import seaborn as sns from sklearn.metrics import confusion_matrix import numpy as np  conf_mx = confusion_matrix(y_test, tree.predict(X_test))  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7)) fig.suptitle('Confusion matrix', c='r') sns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True,              fmt='.2%', cmap='Blues') axes[0].set_xlabel('Predicted labels') axes[0].set_ylabel('Actual labels')  sns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='') axes[1].set_xlabel('Predicted labels') axes[1].set_ylabel('Actual labels'); In\u00a0[52]: Copied! <pre>%%time\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nrandf = RandomForestClassifier()\n\nparams = {\n    'n_estimators': [x for x in range(20, 401, 20)],\n    'max_features': ['log2', 1.0],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 5],\n}\n\ngscv = GridSearchCV(estimator = randf, \n                         return_train_score=True,\n                         param_grid=params,\n                         cv = 5,\n                         verbose=1,\n                         n_jobs = -1)\n\ngscv.fit(X_train, y_train)\n\ngscv.best_params_\n</pre> %%time from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import GridSearchCV  randf = RandomForestClassifier()  params = {     'n_estimators': [x for x in range(20, 401, 20)],     'max_features': ['log2', 1.0],     'min_samples_split': [2, 5, 10],     'min_samples_leaf': [1, 2, 5], }  gscv = GridSearchCV(estimator = randf,                           return_train_score=True,                          param_grid=params,                          cv = 5,                          verbose=1,                          n_jobs = -1)  gscv.fit(X_train, y_train)  gscv.best_params_ <pre>Fitting 5 folds for each of 360 candidates, totalling 1800 fits\nCPU times: user 5.31 s, sys: 635 ms, total: 5.94 s\nWall time: 11min 11s\n</pre> Out[52]: <pre>{'max_features': 'log2',\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 340}</pre> In\u00a0[53]: Copied! <pre>plot_grid_search_validation_curve(gscv, 'n_estimators', ylim=(0.95, 1))\n</pre> plot_grid_search_validation_curve(gscv, 'n_estimators', ylim=(0.95, 1)) In\u00a0[54]: Copied! <pre>rfc = RandomForestClassifier(\n    max_features=\"log2\",\n    min_samples_leaf=1,\n    min_samples_split=2,\n    n_estimators=340,\n    random_state=42\n)\n\nrfc.fit(X_train, y_train)\n\ny_pred = rfc.predict(X_test)\n\naccuracy_score(y_test, y_pred)\n</pre> rfc = RandomForestClassifier(     max_features=\"log2\",     min_samples_leaf=1,     min_samples_split=2,     n_estimators=340,     random_state=42 )  rfc.fit(X_train, y_train)  y_pred = rfc.predict(X_test)  accuracy_score(y_test, y_pred) Out[54]: <pre>0.9723687515699573</pre> In\u00a0[55]: Copied! <pre>feature_names = X.columns.to_list()\n\nfig, ax = plt.subplots(figsize=(40,5))\nax.bar(range(0, X.shape[1]), rfc.feature_importances_)\nax.set_title(\"Feature Importances\")\nax.set_xticks(range(X.shape[1]))\nax.set_xticklabels(feature_names)\nax.grid()\n</pre> feature_names = X.columns.to_list()  fig, ax = plt.subplots(figsize=(40,5)) ax.bar(range(0, X.shape[1]), rfc.feature_importances_) ax.set_title(\"Feature Importances\") ax.set_xticks(range(X.shape[1])) ax.set_xticklabels(feature_names) ax.grid() In\u00a0[56]: Copied! <pre>features = np.array(feature_names)\nfeatures[rfc.feature_importances_.argsort()[::-1]]\nprint(\"Features sorted by their significativity score:\")\nfor i, feature in enumerate(features[rfc.feature_importances_.argsort()[::-1]]):\n    print(f\"{i+1}: {feature}\")\n</pre> features = np.array(feature_names) features[rfc.feature_importances_.argsort()[::-1]] print(\"Features sorted by their significativity score:\") for i, feature in enumerate(features[rfc.feature_importances_.argsort()[::-1]]):     print(f\"{i+1}: {feature}\") <pre>Features sorted by their significativity score:\n1: has_spf\n2: polarity\n3: subjectivity\n4: images\n5: has_dmarc\n6: html\n7: send_date_tz_is_valid\n8: has_dkim\n9: bad_words_percentage\n10: attachments\n11: https_only\n12: subject_is_uppercase\n13: mailto\n14: send_date_is_RFC2822_compliant\n15: domain_matches\n16: links\n17: has_received_date\n18: has_suspect_subject\n19: auth_warn\n20: form\n21: script\n22: uppercase_body\n23: attach_is_executable\n</pre> In\u00a0[57]: Copied! <pre>conf_mx = confusion_matrix(y_test, rfc.predict(X_test))\n\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7))\nfig.suptitle('Confusion matrix', c='r')\nsns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True, \n            fmt='.2%', cmap='Blues')\naxes[0].set_xlabel('Predicted labels')\naxes[0].set_ylabel('Actual labels')\n\nsns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='')\naxes[1].set_xlabel('Predicted labels')\naxes[1].set_ylabel('Actual labels');\n</pre> conf_mx = confusion_matrix(y_test, rfc.predict(X_test))  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7)) fig.suptitle('Confusion matrix', c='r') sns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True,              fmt='.2%', cmap='Blues') axes[0].set_xlabel('Predicted labels') axes[0].set_ylabel('Actual labels')  sns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='') axes[1].set_xlabel('Predicted labels') axes[1].set_ylabel('Actual labels'); In\u00a0[58]: Copied! <pre>import pickle\n\n# fit on entire dataset before saving\nrfc.fit(X, y)\nwith open('/media/matteo/Dati/Progetti/spam-analyzer/conf/classifier.pkl', 'wb') as f:\n    pickle.dump(rfc, f)\n</pre> import pickle  # fit on entire dataset before saving rfc.fit(X, y) with open('/media/matteo/Dati/Progetti/spam-analyzer/conf/classifier.pkl', 'wb') as f:     pickle.dump(rfc, f) In\u00a0[33]: Copied! <pre>from sklearn.neighbors import KNeighborsClassifier\nmaxim = 0\ni = 1\nfor n in range(1, 101):\n    knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n\n    knn.fit(X_train, y_train)\n\n    y_pred = knn.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    if acc &gt; maxim:\n        maxim = acc\n        best = knn\n        i = n\nprint(maxim, \"at index\", i)\n</pre> from sklearn.neighbors import KNeighborsClassifier maxim = 0 i = 1 for n in range(1, 101):     knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)      knn.fit(X_train, y_train)      y_pred = knn.predict(X_test)     acc = accuracy_score(y_test, y_pred)     if acc &gt; maxim:         maxim = acc         best = knn         i = n print(maxim, \"at index\", i) <pre>0.9660889223813113 at index 1\n</pre> In\u00a0[36]: Copied! <pre>y_pred = best.predict(X_test)\naccuracy_score(y_test, y_pred)\n</pre> y_pred = best.predict(X_test) accuracy_score(y_test, y_pred) Out[36]: <pre>0.9228836975634263</pre> In\u00a0[37]: Copied! <pre>conf_mx = confusion_matrix(y_test, best.predict(X_test))\n\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7))\nfig.suptitle('Confusion matrix', c='r')\nsns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True, \n            fmt='.2%', cmap='Blues')\naxes[0].set_xlabel('Predicted labels')\naxes[0].set_ylabel('Actual labels')\n\nsns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='')\naxes[1].set_xlabel('Predicted labels')\naxes[1].set_ylabel('Actual labels');\n</pre> conf_mx = confusion_matrix(y_test, best.predict(X_test))  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7)) fig.suptitle('Confusion matrix', c='r') sns.heatmap(conf_mx/np.sum(conf_mx), ax=axes[0], annot=True,              fmt='.2%', cmap='Blues') axes[0].set_xlabel('Predicted labels') axes[0].set_ylabel('Actual labels')  sns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='') axes[1].set_xlabel('Predicted labels') axes[1].set_ylabel('Actual labels'); In\u00a0[10]: Copied! <pre>import numbers\n\ndef plot_grid_search_validation_curve(grid, param_to_vary,\n                                      title='Validation Curve', ylim=None,\n                                      xlim=None, log=None):\n    \"\"\"Plots train and cross-validation scores from a GridSearchCV instance's\n    best params while varying one of those params.\"\"\"\n\n    df_cv_results = pd.DataFrame(grid.cv_results_)\n    train_scores_mean = df_cv_results['mean_train_score']\n    valid_scores_mean = df_cv_results['mean_test_score']\n    train_scores_std = df_cv_results['std_train_score']\n    valid_scores_std = df_cv_results['std_test_score']\n\n    param_cols = [c for c in df_cv_results.columns if c[:6] == 'param_']\n    param_ranges = [grid.param_grid[p[6:]] for p in param_cols]\n    param_ranges_lengths = [len(pr) for pr in param_ranges]\n\n    train_scores_mean = np.array(train_scores_mean).reshape(*param_ranges_lengths)\n    valid_scores_mean = np.array(valid_scores_mean).reshape(*param_ranges_lengths)\n    train_scores_std = np.array(train_scores_std).reshape(*param_ranges_lengths)\n    valid_scores_std = np.array(valid_scores_std).reshape(*param_ranges_lengths)\n\n    param_to_vary_idx = param_cols.index('param_{}'.format(param_to_vary))\n\n    slices = []\n    for idx, param in enumerate(grid.best_params_):\n        if (idx == param_to_vary_idx):\n            slices.append(slice(None))\n            continue\n        best_param_val = grid.best_params_[param]\n        idx_of_best_param = 0\n        if isinstance(param_ranges[idx], np.ndarray):\n            idx_of_best_param = param_ranges[idx].tolist().index(best_param_val)\n        else:\n            idx_of_best_param = param_ranges[idx].index(best_param_val)\n        slices.append(idx_of_best_param)\n\n    train_scores_mean = train_scores_mean[tuple(slices)]\n    valid_scores_mean = valid_scores_mean[tuple(slices)]\n    train_scores_std = train_scores_std[tuple(slices)]\n    valid_scores_std = valid_scores_std[tuple(slices)]\n\n    plt.clf()\n\n    plt.title(title)\n    plt.xlabel(param_to_vary)\n    plt.ylabel('Score')\n\n    if (ylim is None):\n        plt.ylim(0.0, 1.1)\n    else:\n        plt.ylim(*ylim)\n\n    if (not (xlim is None)):\n        plt.xlim(*xlim)\n\n    lw = 2\n\n    plot_fn = plt.plot\n    if log:\n        plot_fn = plt.semilogx\n\n    param_range = param_ranges[param_to_vary_idx]\n    if (not isinstance(param_range[0], numbers.Number)):\n        param_range = [str(x) for x in param_range]\n    plot_fn(param_range, train_scores_mean, label='Training score', color='r',\n            lw=lw)\n    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color='r', lw=lw)\n    plot_fn(param_range, valid_scores_mean, label='Cross-validation score',\n            color='b', lw=lw)\n    plt.fill_between(param_range, valid_scores_mean - valid_scores_std,\n                     valid_scores_mean + valid_scores_std, alpha=0.1,\n                     color='b', lw=lw)\n\n    plt.legend(loc='lower right')\n\n    plt.show()\n</pre> import numbers  def plot_grid_search_validation_curve(grid, param_to_vary,                                       title='Validation Curve', ylim=None,                                       xlim=None, log=None):     \"\"\"Plots train and cross-validation scores from a GridSearchCV instance's     best params while varying one of those params.\"\"\"      df_cv_results = pd.DataFrame(grid.cv_results_)     train_scores_mean = df_cv_results['mean_train_score']     valid_scores_mean = df_cv_results['mean_test_score']     train_scores_std = df_cv_results['std_train_score']     valid_scores_std = df_cv_results['std_test_score']      param_cols = [c for c in df_cv_results.columns if c[:6] == 'param_']     param_ranges = [grid.param_grid[p[6:]] for p in param_cols]     param_ranges_lengths = [len(pr) for pr in param_ranges]      train_scores_mean = np.array(train_scores_mean).reshape(*param_ranges_lengths)     valid_scores_mean = np.array(valid_scores_mean).reshape(*param_ranges_lengths)     train_scores_std = np.array(train_scores_std).reshape(*param_ranges_lengths)     valid_scores_std = np.array(valid_scores_std).reshape(*param_ranges_lengths)      param_to_vary_idx = param_cols.index('param_{}'.format(param_to_vary))      slices = []     for idx, param in enumerate(grid.best_params_):         if (idx == param_to_vary_idx):             slices.append(slice(None))             continue         best_param_val = grid.best_params_[param]         idx_of_best_param = 0         if isinstance(param_ranges[idx], np.ndarray):             idx_of_best_param = param_ranges[idx].tolist().index(best_param_val)         else:             idx_of_best_param = param_ranges[idx].index(best_param_val)         slices.append(idx_of_best_param)      train_scores_mean = train_scores_mean[tuple(slices)]     valid_scores_mean = valid_scores_mean[tuple(slices)]     train_scores_std = train_scores_std[tuple(slices)]     valid_scores_std = valid_scores_std[tuple(slices)]      plt.clf()      plt.title(title)     plt.xlabel(param_to_vary)     plt.ylabel('Score')      if (ylim is None):         plt.ylim(0.0, 1.1)     else:         plt.ylim(*ylim)      if (not (xlim is None)):         plt.xlim(*xlim)      lw = 2      plot_fn = plt.plot     if log:         plot_fn = plt.semilogx      param_range = param_ranges[param_to_vary_idx]     if (not isinstance(param_range[0], numbers.Number)):         param_range = [str(x) for x in param_range]     plot_fn(param_range, train_scores_mean, label='Training score', color='r',             lw=lw)     plt.fill_between(param_range, train_scores_mean - train_scores_std,                      train_scores_mean + train_scores_std, alpha=0.1,                      color='r', lw=lw)     plot_fn(param_range, valid_scores_mean, label='Cross-validation score',             color='b', lw=lw)     plt.fill_between(param_range, valid_scores_mean - valid_scores_std,                      valid_scores_mean + valid_scores_std, alpha=0.1,                      color='b', lw=lw)      plt.legend(loc='lower right')      plt.show()"},{"location":"data_analysis/SpamAnalysis/#models-evaluation","title":"Models Evaluation\u00b6","text":""},{"location":"data_analysis/SpamAnalysis/#data-visualization","title":"Data visualization\u00b6","text":""},{"location":"data_analysis/SpamAnalysis/#decision-tree","title":"Decision Tree\u00b6","text":""},{"location":"data_analysis/SpamAnalysis/#random-forest","title":"Random Forest\u00b6","text":""},{"location":"data_analysis/SpamAnalysis/#knn","title":"KNN\u00b6","text":""}]}